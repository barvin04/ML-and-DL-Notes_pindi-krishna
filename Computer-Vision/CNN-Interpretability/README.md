# CNN Interpretability Techniques

## Prerequisites

### Interpretability vs Explainability

1. Interpretability :  Interpretability is about the extent to which a cause and effect can be observed within a system. Or, to put it another way, it is the extent to which you are able to predict what is going to happen, given a change in input or algorithmic parameters. It’s being able to look at an algorithm and go yep, I can see what’s happening here.

1. Explainability : Explainability, meanwhile, is the extent to which the internal mechanics of a machine or deep learning system can be explained in human terms. 

1. Interpretability is about being able to discern the mechanics without necessarily knowing why. Explainability is being able to quite literally explain what is happening.


### Why Interpretability ?

We must build ‘transparent’ models that explain why they predict what they predict. 

1. First, when the AI is relatively weaker than the human and not yet reliably ‘deployable’, the goal of transparency and explanations is to identify the failure mode.

1. Second, when the AI is on par with humans and reliably ‘deployable’, the goal is to establish appropriate trust and confidence in users.

1. Third, when the AI is significantly stronger than humans, the goal of the explanations is in machine teaching i.e teaching humans how to take better decisions.
 
 
